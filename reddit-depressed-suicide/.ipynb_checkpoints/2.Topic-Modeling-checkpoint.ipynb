{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second of three notebooks to analyze whether we can distinguish between a depressed note and a suicidal note. In this notebook, I conduct topic modeling for the posts pulled from r/depression and r/SuicideWatch to see if differentiation between the two types of posts can be discerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_depression = pd.read_csv(\"r_depression.csv\",index_col = 0)\n",
    "df_suicide = pd.read_csv(\"r_suicide.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3796, 2)\n",
      "(3714, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure if I'm being annoying and overbearing...</td>\n",
       "      <td>This semester a friend of mine has skipped sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why can't I just be homeless and die in the cold</td>\n",
       "      <td>I dont want to work I dont want to get up I do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m better</td>\n",
       "      <td>I’d officially better and I’m ready to leave t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have therapy and i’m not going</td>\n",
       "      <td>i’ve got a therapy appointment in 1 hour and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This one girl has actually driven me into depr...</td>\n",
       "      <td>This girl and I had known each other for a whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Not sure if I'm being annoying and overbearing...   \n",
       "1   Why can't I just be homeless and die in the cold   \n",
       "2                                         I’m better   \n",
       "3                   i have therapy and i’m not going   \n",
       "4  This one girl has actually driven me into depr...   \n",
       "\n",
       "                                                Body  \n",
       "0  This semester a friend of mine has skipped sev...  \n",
       "1  I dont want to work I dont want to get up I do...  \n",
       "2  I’d officially better and I’m ready to leave t...  \n",
       "3  i’ve got a therapy appointment in 1 hour and i...  \n",
       "4  This girl and I had known each other for a whi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_depression.shape)\n",
    "df_depression.dropna(how = 'any', inplace = True)\n",
    "print(df_depression.shape)\n",
    "df_depression[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 2)\n",
      "(3680, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holy crap I’m back</td>\n",
       "      <td>Is that what this account will be? Pouring my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telling someone not to kill themselves seems a...</td>\n",
       "      <td>Also, stop telling people \"Think about your fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My life is meaningless</td>\n",
       "      <td>\\n\\n\\n\\nI just want to kill myself. I cannot g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this is my last option</td>\n",
       "      <td>It's not that I want to die. It's that I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't think I can do this</td>\n",
       "      <td>I have midterms and the last thing I wanna do ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                 Holy crap I’m back   \n",
       "1  Telling someone not to kill themselves seems a...   \n",
       "2                             My life is meaningless   \n",
       "3                     I think this is my last option   \n",
       "4                        I don't think I can do this   \n",
       "\n",
       "                                                Body  \n",
       "0  Is that what this account will be? Pouring my ...  \n",
       "1  Also, stop telling people \"Think about your fa...  \n",
       "2  \\n\\n\\n\\nI just want to kill myself. I cannot g...  \n",
       "3  It's not that I want to die. It's that I have ...  \n",
       "4  I have midterms and the last thing I wanna do ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_suicide.shape)\n",
    "df_suicide.dropna(how = 'any', inplace = True)\n",
    "print(df_suicide.shape)\n",
    "df_suicide[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level steps: \n",
    "for each dataframe:\n",
    "1. preprocess: merge the two columns (title + body), tokenize, remove stopwords, lemmatize\n",
    "2. topic modeling\n",
    "\n",
    "then concatenate the two dataframe (by rows) and perform topic modeling again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Topic modeling for r/Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure if I'm being annoying and overbearing...</td>\n",
       "      <td>This semester a friend of mine has skipped sev...</td>\n",
       "      <td>Not sure if I'm being annoying and overbearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why can't I just be homeless and die in the cold</td>\n",
       "      <td>I dont want to work I dont want to get up I do...</td>\n",
       "      <td>Why can't I just be homeless and die in the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m better</td>\n",
       "      <td>I’d officially better and I’m ready to leave t...</td>\n",
       "      <td>I’m better I’d officially better and I’m ready...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have therapy and i’m not going</td>\n",
       "      <td>i’ve got a therapy appointment in 1 hour and i...</td>\n",
       "      <td>i have therapy and i’m not going i’ve got a th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This one girl has actually driven me into depr...</td>\n",
       "      <td>This girl and I had known each other for a whi...</td>\n",
       "      <td>This one girl has actually driven me into depr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Not sure if I'm being annoying and overbearing...   \n",
       "1   Why can't I just be homeless and die in the cold   \n",
       "2                                         I’m better   \n",
       "3                   i have therapy and i’m not going   \n",
       "4  This one girl has actually driven me into depr...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  This semester a friend of mine has skipped sev...   \n",
       "1  I dont want to work I dont want to get up I do...   \n",
       "2  I’d officially better and I’m ready to leave t...   \n",
       "3  i’ve got a therapy appointment in 1 hour and i...   \n",
       "4  This girl and I had known each other for a whi...   \n",
       "\n",
       "                                            Combined  \n",
       "0  Not sure if I'm being annoying and overbearing...  \n",
       "1  Why can't I just be homeless and die in the co...  \n",
       "2  I’m better I’d officially better and I’m ready...  \n",
       "3  i have therapy and i’m not going i’ve got a th...  \n",
       "4  This one girl has actually driven me into depr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge title and body for comprehensive analysis\n",
    "df_depression['Combined'] = df_depression['Title']+' '+ df_depression['Body']\n",
    "df_depression[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jenny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jenny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jenny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# prep for preprocessing\n",
    "# tokenization\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "# stopword\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# lemmatization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mainstream', 'depression', 'anxiety', 'ruing', 'empathy', 'people']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "def preprocess(post):\n",
    "    \"\"\"\n",
    "    preprocess (tokenize, remove stopwords, lemmatize) a post for topic modeling\n",
    "    args:\n",
    "        post (string): one string object that user would like to process\n",
    "    returns:\n",
    "        a list of words\n",
    "    \"\"\"\n",
    "    word_tokens = word_tokenize(post) # tokenize words\n",
    "    filtered_sentence = [word.lower() for word in word_tokens if word not in stop_words] # remove stopwords\n",
    "    filtered_sentence_2 = [word for word in filtered_sentence if not re.match(r\"^\\W+$\", word)] # remove standalone punctuations\n",
    "    filtered_sentence_3 = [re.sub(r\"\\W+\", \"\", word) for word in filtered_sentence_2] # delete any non-word characters (e.g., '')\n",
    "    \n",
    "    # lemmatize\n",
    "    lemmatized = []\n",
    "    for word in filtered_sentence_3:\n",
    "        lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized\n",
    "\n",
    "# test\n",
    "preprocess(\"Mainstream of 'depression and anxiety' is ruing the empathy for people that have it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure if I'm being annoying and overbearing...</td>\n",
       "      <td>This semester a friend of mine has skipped sev...</td>\n",
       "      <td>Not sure if I'm being annoying and overbearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why can't I just be homeless and die in the cold</td>\n",
       "      <td>I dont want to work I dont want to get up I do...</td>\n",
       "      <td>Why can't I just be homeless and die in the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m better</td>\n",
       "      <td>I’d officially better and I’m ready to leave t...</td>\n",
       "      <td>I’m better I’d officially better and I’m ready...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have therapy and i’m not going</td>\n",
       "      <td>i’ve got a therapy appointment in 1 hour and i...</td>\n",
       "      <td>i have therapy and i’m not going i’ve got a th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This one girl has actually driven me into depr...</td>\n",
       "      <td>This girl and I had known each other for a whi...</td>\n",
       "      <td>This one girl has actually driven me into depr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Not sure if I'm being annoying and overbearing...   \n",
       "1   Why can't I just be homeless and die in the cold   \n",
       "2                                         I’m better   \n",
       "3                   i have therapy and i’m not going   \n",
       "4  This one girl has actually driven me into depr...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  This semester a friend of mine has skipped sev...   \n",
       "1  I dont want to work I dont want to get up I do...   \n",
       "2  I’d officially better and I’m ready to leave t...   \n",
       "3  i’ve got a therapy appointment in 1 hour and i...   \n",
       "4  This girl and I had known each other for a whi...   \n",
       "\n",
       "                                            Combined  \n",
       "0  Not sure if I'm being annoying and overbearing...  \n",
       "1  Why can't I just be homeless and die in the co...  \n",
       "2  I’m better I’d officially better and I’m ready...  \n",
       "3  i have therapy and i’m not going i’ve got a th...  \n",
       "4  This one girl has actually driven me into depr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_depression['Combined'] = df_depression['Combined'].astype('str')\n",
    "df_depression[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare document-term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = df_depression['Combined'].values\n",
    "vectorizer = CountVectorizer(tokenizer = preprocess, # use our own preprocessor that tokenizes, removes stopwords, and lemmatizes\n",
    "                            min_df = 15)\n",
    "depression_dtm = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0', '1', '10', '100', '11']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))\n",
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 288114 (3714, 2004)\n"
     ]
    }
   ],
   "source": [
    "X = depression_dtm.toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "titles = df_depression.index.values\n",
    "\n",
    "print(type(X), X.sum(), X.shape) # an array may be needed for lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 3714\n",
      "INFO:lda:vocab_size: 2004\n",
      "INFO:lda:n_words: 288114\n",
      "INFO:lda:n_topics: 5\n",
      "INFO:lda:n_iter: 1500\n",
      "INFO:lda:<0> log likelihood: -2437687\n",
      "INFO:lda:<10> log likelihood: -2202905\n",
      "INFO:lda:<20> log likelihood: -2141844\n",
      "INFO:lda:<30> log likelihood: -2113252\n",
      "INFO:lda:<40> log likelihood: -2096042\n",
      "INFO:lda:<50> log likelihood: -2083532\n",
      "INFO:lda:<60> log likelihood: -2073214\n",
      "INFO:lda:<70> log likelihood: -2066408\n",
      "INFO:lda:<80> log likelihood: -2061395\n",
      "INFO:lda:<90> log likelihood: -2056455\n",
      "INFO:lda:<100> log likelihood: -2052748\n",
      "INFO:lda:<110> log likelihood: -2049825\n",
      "INFO:lda:<120> log likelihood: -2050034\n",
      "INFO:lda:<130> log likelihood: -2047948\n",
      "INFO:lda:<140> log likelihood: -2048064\n",
      "INFO:lda:<150> log likelihood: -2046765\n",
      "INFO:lda:<160> log likelihood: -2045989\n",
      "INFO:lda:<170> log likelihood: -2045036\n",
      "INFO:lda:<180> log likelihood: -2045671\n",
      "INFO:lda:<190> log likelihood: -2045744\n",
      "INFO:lda:<200> log likelihood: -2045191\n",
      "INFO:lda:<210> log likelihood: -2044249\n",
      "INFO:lda:<220> log likelihood: -2043238\n",
      "INFO:lda:<230> log likelihood: -2042550\n",
      "INFO:lda:<240> log likelihood: -2043110\n",
      "INFO:lda:<250> log likelihood: -2043124\n",
      "INFO:lda:<260> log likelihood: -2042744\n",
      "INFO:lda:<270> log likelihood: -2043131\n",
      "INFO:lda:<280> log likelihood: -2042679\n",
      "INFO:lda:<290> log likelihood: -2042956\n",
      "INFO:lda:<300> log likelihood: -2042880\n",
      "INFO:lda:<310> log likelihood: -2042242\n",
      "INFO:lda:<320> log likelihood: -2042810\n",
      "INFO:lda:<330> log likelihood: -2041223\n",
      "INFO:lda:<340> log likelihood: -2042288\n",
      "INFO:lda:<350> log likelihood: -2042096\n",
      "INFO:lda:<360> log likelihood: -2042772\n",
      "INFO:lda:<370> log likelihood: -2041465\n",
      "INFO:lda:<380> log likelihood: -2041052\n",
      "INFO:lda:<390> log likelihood: -2040814\n",
      "INFO:lda:<400> log likelihood: -2040252\n",
      "INFO:lda:<410> log likelihood: -2041008\n",
      "INFO:lda:<420> log likelihood: -2038788\n",
      "INFO:lda:<430> log likelihood: -2040379\n",
      "INFO:lda:<440> log likelihood: -2039552\n",
      "INFO:lda:<450> log likelihood: -2040569\n",
      "INFO:lda:<460> log likelihood: -2040057\n",
      "INFO:lda:<470> log likelihood: -2039719\n",
      "INFO:lda:<480> log likelihood: -2039258\n",
      "INFO:lda:<490> log likelihood: -2039905\n",
      "INFO:lda:<500> log likelihood: -2039419\n",
      "INFO:lda:<510> log likelihood: -2039691\n",
      "INFO:lda:<520> log likelihood: -2039686\n",
      "INFO:lda:<530> log likelihood: -2039067\n",
      "INFO:lda:<540> log likelihood: -2039218\n",
      "INFO:lda:<550> log likelihood: -2039046\n",
      "INFO:lda:<560> log likelihood: -2037959\n",
      "INFO:lda:<570> log likelihood: -2039047\n",
      "INFO:lda:<580> log likelihood: -2038879\n",
      "INFO:lda:<590> log likelihood: -2039489\n",
      "INFO:lda:<600> log likelihood: -2037855\n",
      "INFO:lda:<610> log likelihood: -2038596\n",
      "INFO:lda:<620> log likelihood: -2038927\n",
      "INFO:lda:<630> log likelihood: -2039186\n",
      "INFO:lda:<640> log likelihood: -2037664\n",
      "INFO:lda:<650> log likelihood: -2039540\n",
      "INFO:lda:<660> log likelihood: -2038948\n",
      "INFO:lda:<670> log likelihood: -2039140\n",
      "INFO:lda:<680> log likelihood: -2037561\n",
      "INFO:lda:<690> log likelihood: -2038117\n",
      "INFO:lda:<700> log likelihood: -2038607\n",
      "INFO:lda:<710> log likelihood: -2038269\n",
      "INFO:lda:<720> log likelihood: -2038767\n",
      "INFO:lda:<730> log likelihood: -2038420\n",
      "INFO:lda:<740> log likelihood: -2037732\n",
      "INFO:lda:<750> log likelihood: -2037466\n",
      "INFO:lda:<760> log likelihood: -2038170\n",
      "INFO:lda:<770> log likelihood: -2037056\n",
      "INFO:lda:<780> log likelihood: -2037810\n",
      "INFO:lda:<790> log likelihood: -2037666\n",
      "INFO:lda:<800> log likelihood: -2037373\n",
      "INFO:lda:<810> log likelihood: -2037695\n",
      "INFO:lda:<820> log likelihood: -2036761\n",
      "INFO:lda:<830> log likelihood: -2036879\n",
      "INFO:lda:<840> log likelihood: -2038225\n",
      "INFO:lda:<850> log likelihood: -2037164\n",
      "INFO:lda:<860> log likelihood: -2036847\n",
      "INFO:lda:<870> log likelihood: -2037487\n",
      "INFO:lda:<880> log likelihood: -2036686\n",
      "INFO:lda:<890> log likelihood: -2037664\n",
      "INFO:lda:<900> log likelihood: -2037434\n",
      "INFO:lda:<910> log likelihood: -2037071\n",
      "INFO:lda:<920> log likelihood: -2037646\n",
      "INFO:lda:<930> log likelihood: -2037171\n",
      "INFO:lda:<940> log likelihood: -2037350\n",
      "INFO:lda:<950> log likelihood: -2037198\n",
      "INFO:lda:<960> log likelihood: -2036525\n",
      "INFO:lda:<970> log likelihood: -2037054\n",
      "INFO:lda:<980> log likelihood: -2036937\n",
      "INFO:lda:<990> log likelihood: -2035945\n",
      "INFO:lda:<1000> log likelihood: -2035511\n",
      "INFO:lda:<1010> log likelihood: -2036795\n",
      "INFO:lda:<1020> log likelihood: -2035518\n",
      "INFO:lda:<1030> log likelihood: -2036594\n",
      "INFO:lda:<1040> log likelihood: -2037553\n",
      "INFO:lda:<1050> log likelihood: -2037498\n",
      "INFO:lda:<1060> log likelihood: -2037841\n",
      "INFO:lda:<1070> log likelihood: -2037281\n",
      "INFO:lda:<1080> log likelihood: -2035780\n",
      "INFO:lda:<1090> log likelihood: -2037642\n",
      "INFO:lda:<1100> log likelihood: -2037954\n",
      "INFO:lda:<1110> log likelihood: -2037428\n",
      "INFO:lda:<1120> log likelihood: -2037155\n",
      "INFO:lda:<1130> log likelihood: -2036894\n",
      "INFO:lda:<1140> log likelihood: -2035926\n",
      "INFO:lda:<1150> log likelihood: -2036491\n",
      "INFO:lda:<1160> log likelihood: -2037483\n",
      "INFO:lda:<1170> log likelihood: -2036577\n",
      "INFO:lda:<1180> log likelihood: -2036491\n",
      "INFO:lda:<1190> log likelihood: -2036826\n",
      "INFO:lda:<1200> log likelihood: -2036066\n",
      "INFO:lda:<1210> log likelihood: -2036743\n",
      "INFO:lda:<1220> log likelihood: -2035688\n",
      "INFO:lda:<1230> log likelihood: -2035831\n",
      "INFO:lda:<1240> log likelihood: -2036242\n",
      "INFO:lda:<1250> log likelihood: -2036091\n",
      "INFO:lda:<1260> log likelihood: -2035910\n",
      "INFO:lda:<1270> log likelihood: -2035812\n",
      "INFO:lda:<1280> log likelihood: -2035368\n",
      "INFO:lda:<1290> log likelihood: -2036522\n",
      "INFO:lda:<1300> log likelihood: -2036332\n",
      "INFO:lda:<1310> log likelihood: -2035659\n",
      "INFO:lda:<1320> log likelihood: -2035640\n",
      "INFO:lda:<1330> log likelihood: -2035511\n",
      "INFO:lda:<1340> log likelihood: -2034630\n",
      "INFO:lda:<1350> log likelihood: -2035795\n",
      "INFO:lda:<1360> log likelihood: -2034542\n",
      "INFO:lda:<1370> log likelihood: -2035518\n",
      "INFO:lda:<1380> log likelihood: -2034131\n",
      "INFO:lda:<1390> log likelihood: -2034177\n",
      "INFO:lda:<1400> log likelihood: -2034147\n",
      "INFO:lda:<1410> log likelihood: -2033571\n",
      "INFO:lda:<1420> log likelihood: -2034163\n",
      "INFO:lda:<1430> log likelihood: -2034491\n",
      "INFO:lda:<1440> log likelihood: -2034231\n",
      "INFO:lda:<1450> log likelihood: -2035452\n",
      "INFO:lda:<1460> log likelihood: -2035234\n",
      "INFO:lda:<1470> log likelihood: -2036660\n",
      "INFO:lda:<1480> log likelihood: -2035482\n",
      "INFO:lda:<1490> log likelihood: -2035361\n",
      "INFO:lda:<1499> log likelihood: -2035550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: nt/m/s/ve/ca/like/feel/want/know/life/ll/re/even/get/d/really/people/anymore/one/thing\n",
      "Topic 1: emptiness/im/dont/cant/ive/help/didnt/need/tired/hate/wont/thats/want/doesnt/shes/please/wasnt/havent/isnt/there\n",
      "Topic 2: year/friend/school/got/job/time/get/go/day/would/back/told/one/month/work/mom/home/want/parent/life\n",
      "Topic 3: feel/like/depression/get/time/help/day/know/really/thing/life/even/make/thought/feeling/people/year/work/depressed/go\n",
      "Topic 4: feel/like/want/know/life/people/even/friend/make/get/thing/fucking/time/never/one/really/think/would/hate/someone\n"
     ]
    }
   ],
   "source": [
    "# get topics with LDA\n",
    "import numpy as np\n",
    "import lda\n",
    "\n",
    "model = lda.LDA(n_topics=5, n_iter=1500, random_state=1) # 5 topics seem to be too much, but 4 seem confused\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 20\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, '/'.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The four-five topics that people are depressed about seem to be\n",
    "\n",
    "- confused: feel, even, anymore\n",
    "- lonely and depressed: emptiness, can't, tired, hate \n",
    "- people and career: friend, school, job, work, mom, parent\n",
    "- mental health: depression, feeling, depressed \n",
    "- anger (more ambiguous): life, fucking, never, hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the top topic of each post\n",
    "doc_topic = model.doc_topic_\n",
    "topic_index = {0:'confused', 1: 'lonely', 2:'people_career', 3:'mental_health', 4:'anger'}\n",
    "topic_count = {v : 0 for v in topic_index.values()}\n",
    "for i in range(len(titles)):\n",
    "    topic_count[topic_index[doc_topic[i].argmax()]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confused': 234,\n",
       " 'lonely': 11,\n",
       " 'people_career': 721,\n",
       " 'mental_health': 1156,\n",
       " 'anger': 1592}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # check each topic\n",
    "# for i in range(len(titles)):\n",
    "#     if doc_topic[i].argmax() == 3:\n",
    "#         print(df_depression['Combined'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Topic modeling for r/SuicideWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holy crap I’m back</td>\n",
       "      <td>Is that what this account will be? Pouring my ...</td>\n",
       "      <td>Holy crap I’m back Is that what this account w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telling someone not to kill themselves seems a...</td>\n",
       "      <td>Also, stop telling people \"Think about your fa...</td>\n",
       "      <td>Telling someone not to kill themselves seems a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My life is meaningless</td>\n",
       "      <td>\\n\\n\\n\\nI just want to kill myself. I cannot g...</td>\n",
       "      <td>My life is meaningless \\n\\n\\n\\nI just want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this is my last option</td>\n",
       "      <td>It's not that I want to die. It's that I have ...</td>\n",
       "      <td>I think this is my last option It's not that I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't think I can do this</td>\n",
       "      <td>I have midterms and the last thing I wanna do ...</td>\n",
       "      <td>I don't think I can do this I have midterms an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                 Holy crap I’m back   \n",
       "1  Telling someone not to kill themselves seems a...   \n",
       "2                             My life is meaningless   \n",
       "3                     I think this is my last option   \n",
       "4                        I don't think I can do this   \n",
       "\n",
       "                                                Body  \\\n",
       "0  Is that what this account will be? Pouring my ...   \n",
       "1  Also, stop telling people \"Think about your fa...   \n",
       "2  \\n\\n\\n\\nI just want to kill myself. I cannot g...   \n",
       "3  It's not that I want to die. It's that I have ...   \n",
       "4  I have midterms and the last thing I wanna do ...   \n",
       "\n",
       "                                            Combined  \n",
       "0  Holy crap I’m back Is that what this account w...  \n",
       "1  Telling someone not to kill themselves seems a...  \n",
       "2  My life is meaningless \\n\\n\\n\\nI just want to ...  \n",
       "3  I think this is my last option It's not that I...  \n",
       "4  I don't think I can do this I have midterms an...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge two columns\n",
    "df_suicide['Combined'] = df_suicide['Title']+' '+ df_suicide['Body']\n",
    "df_suicide[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holy crap I’m back</td>\n",
       "      <td>Is that what this account will be? Pouring my ...</td>\n",
       "      <td>Holy crap I’m back Is that what this account w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telling someone not to kill themselves seems a...</td>\n",
       "      <td>Also, stop telling people \"Think about your fa...</td>\n",
       "      <td>Telling someone not to kill themselves seems a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My life is meaningless</td>\n",
       "      <td>\\n\\n\\n\\nI just want to kill myself. I cannot g...</td>\n",
       "      <td>My life is meaningless \\n\\n\\n\\nI just want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this is my last option</td>\n",
       "      <td>It's not that I want to die. It's that I have ...</td>\n",
       "      <td>I think this is my last option It's not that I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't think I can do this</td>\n",
       "      <td>I have midterms and the last thing I wanna do ...</td>\n",
       "      <td>I don't think I can do this I have midterms an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                 Holy crap I’m back   \n",
       "1  Telling someone not to kill themselves seems a...   \n",
       "2                             My life is meaningless   \n",
       "3                     I think this is my last option   \n",
       "4                        I don't think I can do this   \n",
       "\n",
       "                                                Body  \\\n",
       "0  Is that what this account will be? Pouring my ...   \n",
       "1  Also, stop telling people \"Think about your fa...   \n",
       "2  \\n\\n\\n\\nI just want to kill myself. I cannot g...   \n",
       "3  It's not that I want to die. It's that I have ...   \n",
       "4  I have midterms and the last thing I wanna do ...   \n",
       "\n",
       "                                            Combined  \n",
       "0  Holy crap I’m back Is that what this account w...  \n",
       "1  Telling someone not to kill themselves seems a...  \n",
       "2  My life is meaningless \\n\\n\\n\\nI just want to ...  \n",
       "3  I think this is my last option It's not that I...  \n",
       "4  I don't think I can do this I have midterms an...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_suicide['Combined'] = df_suicide['Combined'].astype('str')\n",
    "df_suicide[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare document-term matrix\n",
    "corpus_2 = df_suicide['Combined'].values\n",
    "vectorizer = CountVectorizer(tokenizer = preprocess, # use our own preprocessor that tokenizes, removes stopwords, and lemmatizes\n",
    "                            min_df = 15)\n",
    "suicide_dtm = vectorizer.fit_transform(corpus_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0', '1', '10', '100', '11']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))\n",
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 281251 (3680, 1957)\n"
     ]
    }
   ],
   "source": [
    "X = suicide_dtm.toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "titles = df_suicide.index.values\n",
    "\n",
    "print(type(X), X.sum(), X.shape) # an array may be needed for lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 3680\n",
      "INFO:lda:vocab_size: 1957\n",
      "INFO:lda:n_words: 281251\n",
      "INFO:lda:n_topics: 3\n",
      "INFO:lda:n_iter: 1500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -2186687\n",
      "INFO:lda:<10> log likelihood: -2056377\n",
      "INFO:lda:<20> log likelihood: -2012810\n",
      "INFO:lda:<30> log likelihood: -1981041\n",
      "INFO:lda:<40> log likelihood: -1958350\n",
      "INFO:lda:<50> log likelihood: -1940562\n",
      "INFO:lda:<60> log likelihood: -1930191\n",
      "INFO:lda:<70> log likelihood: -1925771\n",
      "INFO:lda:<80> log likelihood: -1922929\n",
      "INFO:lda:<90> log likelihood: -1921691\n",
      "INFO:lda:<100> log likelihood: -1920409\n",
      "INFO:lda:<110> log likelihood: -1920617\n",
      "INFO:lda:<120> log likelihood: -1919763\n",
      "INFO:lda:<130> log likelihood: -1917280\n",
      "INFO:lda:<140> log likelihood: -1917494\n",
      "INFO:lda:<150> log likelihood: -1917251\n",
      "INFO:lda:<160> log likelihood: -1916453\n",
      "INFO:lda:<170> log likelihood: -1916141\n",
      "INFO:lda:<180> log likelihood: -1915471\n",
      "INFO:lda:<190> log likelihood: -1915435\n",
      "INFO:lda:<200> log likelihood: -1915269\n",
      "INFO:lda:<210> log likelihood: -1914500\n",
      "INFO:lda:<220> log likelihood: -1912205\n",
      "INFO:lda:<230> log likelihood: -1912196\n",
      "INFO:lda:<240> log likelihood: -1910616\n",
      "INFO:lda:<250> log likelihood: -1910205\n",
      "INFO:lda:<260> log likelihood: -1909331\n",
      "INFO:lda:<270> log likelihood: -1908014\n",
      "INFO:lda:<280> log likelihood: -1906735\n",
      "INFO:lda:<290> log likelihood: -1904746\n",
      "INFO:lda:<300> log likelihood: -1903226\n",
      "INFO:lda:<310> log likelihood: -1901557\n",
      "INFO:lda:<320> log likelihood: -1899522\n",
      "INFO:lda:<330> log likelihood: -1897591\n",
      "INFO:lda:<340> log likelihood: -1895643\n",
      "INFO:lda:<350> log likelihood: -1893703\n",
      "INFO:lda:<360> log likelihood: -1891393\n",
      "INFO:lda:<370> log likelihood: -1889292\n",
      "INFO:lda:<380> log likelihood: -1887818\n",
      "INFO:lda:<390> log likelihood: -1886148\n",
      "INFO:lda:<400> log likelihood: -1883859\n",
      "INFO:lda:<410> log likelihood: -1882673\n",
      "INFO:lda:<420> log likelihood: -1880648\n",
      "INFO:lda:<430> log likelihood: -1878797\n",
      "INFO:lda:<440> log likelihood: -1878649\n",
      "INFO:lda:<450> log likelihood: -1877400\n",
      "INFO:lda:<460> log likelihood: -1876462\n",
      "INFO:lda:<470> log likelihood: -1876241\n",
      "INFO:lda:<480> log likelihood: -1875708\n",
      "INFO:lda:<490> log likelihood: -1874433\n",
      "INFO:lda:<500> log likelihood: -1874490\n",
      "INFO:lda:<510> log likelihood: -1872780\n",
      "INFO:lda:<520> log likelihood: -1872721\n",
      "INFO:lda:<530> log likelihood: -1872745\n",
      "INFO:lda:<540> log likelihood: -1871936\n",
      "INFO:lda:<550> log likelihood: -1870958\n",
      "INFO:lda:<560> log likelihood: -1869798\n",
      "INFO:lda:<570> log likelihood: -1869637\n",
      "INFO:lda:<580> log likelihood: -1868793\n",
      "INFO:lda:<590> log likelihood: -1868513\n",
      "INFO:lda:<600> log likelihood: -1867649\n",
      "INFO:lda:<610> log likelihood: -1867609\n",
      "INFO:lda:<620> log likelihood: -1868267\n",
      "INFO:lda:<630> log likelihood: -1867893\n",
      "INFO:lda:<640> log likelihood: -1867017\n",
      "INFO:lda:<650> log likelihood: -1866665\n",
      "INFO:lda:<660> log likelihood: -1867977\n",
      "INFO:lda:<670> log likelihood: -1866567\n",
      "INFO:lda:<680> log likelihood: -1866561\n",
      "INFO:lda:<690> log likelihood: -1866771\n",
      "INFO:lda:<700> log likelihood: -1866925\n",
      "INFO:lda:<710> log likelihood: -1867025\n",
      "INFO:lda:<720> log likelihood: -1867212\n",
      "INFO:lda:<730> log likelihood: -1866130\n",
      "INFO:lda:<740> log likelihood: -1866276\n",
      "INFO:lda:<750> log likelihood: -1865847\n",
      "INFO:lda:<760> log likelihood: -1865613\n",
      "INFO:lda:<770> log likelihood: -1866049\n",
      "INFO:lda:<780> log likelihood: -1866056\n",
      "INFO:lda:<790> log likelihood: -1865055\n",
      "INFO:lda:<800> log likelihood: -1865271\n",
      "INFO:lda:<810> log likelihood: -1865472\n",
      "INFO:lda:<820> log likelihood: -1865639\n",
      "INFO:lda:<830> log likelihood: -1864829\n",
      "INFO:lda:<840> log likelihood: -1864377\n",
      "INFO:lda:<850> log likelihood: -1865159\n",
      "INFO:lda:<860> log likelihood: -1865331\n",
      "INFO:lda:<870> log likelihood: -1865480\n",
      "INFO:lda:<880> log likelihood: -1864622\n",
      "INFO:lda:<890> log likelihood: -1864400\n",
      "INFO:lda:<900> log likelihood: -1864309\n",
      "INFO:lda:<910> log likelihood: -1865058\n",
      "INFO:lda:<920> log likelihood: -1864843\n",
      "INFO:lda:<930> log likelihood: -1863627\n",
      "INFO:lda:<940> log likelihood: -1863243\n",
      "INFO:lda:<950> log likelihood: -1864215\n",
      "INFO:lda:<960> log likelihood: -1863298\n",
      "INFO:lda:<970> log likelihood: -1864756\n",
      "INFO:lda:<980> log likelihood: -1863922\n",
      "INFO:lda:<990> log likelihood: -1863506\n",
      "INFO:lda:<1000> log likelihood: -1863670\n",
      "INFO:lda:<1010> log likelihood: -1863513\n",
      "INFO:lda:<1020> log likelihood: -1863520\n",
      "INFO:lda:<1030> log likelihood: -1863310\n",
      "INFO:lda:<1040> log likelihood: -1863435\n",
      "INFO:lda:<1050> log likelihood: -1864044\n",
      "INFO:lda:<1060> log likelihood: -1864321\n",
      "INFO:lda:<1070> log likelihood: -1863642\n",
      "INFO:lda:<1080> log likelihood: -1863127\n",
      "INFO:lda:<1090> log likelihood: -1862534\n",
      "INFO:lda:<1100> log likelihood: -1863122\n",
      "INFO:lda:<1110> log likelihood: -1862845\n",
      "INFO:lda:<1120> log likelihood: -1862323\n",
      "INFO:lda:<1130> log likelihood: -1863337\n",
      "INFO:lda:<1140> log likelihood: -1863083\n",
      "INFO:lda:<1150> log likelihood: -1862759\n",
      "INFO:lda:<1160> log likelihood: -1863074\n",
      "INFO:lda:<1170> log likelihood: -1863647\n",
      "INFO:lda:<1180> log likelihood: -1863296\n",
      "INFO:lda:<1190> log likelihood: -1862554\n",
      "INFO:lda:<1200> log likelihood: -1862681\n",
      "INFO:lda:<1210> log likelihood: -1862729\n",
      "INFO:lda:<1220> log likelihood: -1863058\n",
      "INFO:lda:<1230> log likelihood: -1863695\n",
      "INFO:lda:<1240> log likelihood: -1863117\n",
      "INFO:lda:<1250> log likelihood: -1861944\n",
      "INFO:lda:<1260> log likelihood: -1862344\n",
      "INFO:lda:<1270> log likelihood: -1862534\n",
      "INFO:lda:<1280> log likelihood: -1862540\n",
      "INFO:lda:<1290> log likelihood: -1862310\n",
      "INFO:lda:<1300> log likelihood: -1861193\n",
      "INFO:lda:<1310> log likelihood: -1860609\n",
      "INFO:lda:<1320> log likelihood: -1861158\n",
      "INFO:lda:<1330> log likelihood: -1862158\n",
      "INFO:lda:<1340> log likelihood: -1861484\n",
      "INFO:lda:<1350> log likelihood: -1861475\n",
      "INFO:lda:<1360> log likelihood: -1861163\n",
      "INFO:lda:<1370> log likelihood: -1860825\n",
      "INFO:lda:<1380> log likelihood: -1861299\n",
      "INFO:lda:<1390> log likelihood: -1860626\n",
      "INFO:lda:<1400> log likelihood: -1860871\n",
      "INFO:lda:<1410> log likelihood: -1860483\n",
      "INFO:lda:<1420> log likelihood: -1860041\n",
      "INFO:lda:<1430> log likelihood: -1860730\n",
      "INFO:lda:<1440> log likelihood: -1860844\n",
      "INFO:lda:<1450> log likelihood: -1860235\n",
      "INFO:lda:<1460> log likelihood: -1860061\n",
      "INFO:lda:<1470> log likelihood: -1860760\n",
      "INFO:lda:<1480> log likelihood: -1860087\n",
      "INFO:lda:<1490> log likelihood: -1860096\n",
      "INFO:lda:<1499> log likelihood: -1859959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: like/feel/life/want/know/time/get/year/even/would/friend/people/thing/go/really/day/think/make/going/never\n",
      "Topic 1: nt/m/s/ve/ca/want/ll/like/know/feel/life/fucking/get/die/d/people/anymore/help/even/kill\n",
      "Topic 2: one/care/im/dont/kill/cant/ive/doesnt/thats/ill/isnt/there/wont/wouldnt/didnt/he/havent/shes/id/now\n"
     ]
    }
   ],
   "source": [
    "# get topics with LDA\n",
    "import numpy as np\n",
    "import lda\n",
    "\n",
    "model = lda.LDA(n_topics=3, n_iter=1500, random_state=1) # the topics seem to overlap quite a bit; limiting to 3 topics\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 20\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, '/'.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The three topics that people are suicidal over seem to be\n",
    "\n",
    "- help-seeking? feel, friend, people, think\n",
    "- anger and given up? feel, fucking, die, anymore, kill\n",
    "- ...everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the top topic of each post\n",
    "doc_topic = model.doc_topic_\n",
    "topic_index = {0:'help-seeking', 1: 'anger', 2:'everything'}\n",
    "topic_count = {v : 0 for v in topic_index.values()}\n",
    "for i in range(len(titles)):\n",
    "    topic_count[topic_index[doc_topic[i].argmax()]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'help-seeking': 3421, 'anger': 256, 'everything': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # check each topic\n",
    "# for i in range(len(titles)):\n",
    "#     if doc_topic[i].argmax() == 2:\n",
    "#         print(df_suicide['Combined'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topic modeling for concatenated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7394, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure if I'm being annoying and overbearing...</td>\n",
       "      <td>This semester a friend of mine has skipped sev...</td>\n",
       "      <td>Not sure if I'm being annoying and overbearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why can't I just be homeless and die in the cold</td>\n",
       "      <td>I dont want to work I dont want to get up I do...</td>\n",
       "      <td>Why can't I just be homeless and die in the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m better</td>\n",
       "      <td>I’d officially better and I’m ready to leave t...</td>\n",
       "      <td>I’m better I’d officially better and I’m ready...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have therapy and i’m not going</td>\n",
       "      <td>i’ve got a therapy appointment in 1 hour and i...</td>\n",
       "      <td>i have therapy and i’m not going i’ve got a th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This one girl has actually driven me into depr...</td>\n",
       "      <td>This girl and I had known each other for a whi...</td>\n",
       "      <td>This one girl has actually driven me into depr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Not sure if I'm being annoying and overbearing...   \n",
       "1   Why can't I just be homeless and die in the cold   \n",
       "2                                         I’m better   \n",
       "3                   i have therapy and i’m not going   \n",
       "4  This one girl has actually driven me into depr...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  This semester a friend of mine has skipped sev...   \n",
       "1  I dont want to work I dont want to get up I do...   \n",
       "2  I’d officially better and I’m ready to leave t...   \n",
       "3  i’ve got a therapy appointment in 1 hour and i...   \n",
       "4  This girl and I had known each other for a whi...   \n",
       "\n",
       "                                            Combined  \n",
       "0  Not sure if I'm being annoying and overbearing...  \n",
       "1  Why can't I just be homeless and die in the co...  \n",
       "2  I’m better I’d officially better and I’m ready...  \n",
       "3  i have therapy and i’m not going i’ve got a th...  \n",
       "4  This one girl has actually driven me into depr...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both = pd.concat([df_depression, df_suicide],ignore_index=True).dropna(how = 'any') #reset the index since both were #'s\n",
    "print(df_both.shape)\n",
    "df_both[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare document-term matrix\n",
    "corpus_3 = df_both['Combined'].values\n",
    "vectorizer = CountVectorizer(tokenizer = preprocess, # use our own preprocessor that tokenizes, removes stopwords, and lemmatizes\n",
    "                            min_df = 15)\n",
    "both_dtm = vectorizer.fit_transform(corpus_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0', '1', '10', '100', '1000']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))\n",
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 591620 (7394, 3031)\n"
     ]
    }
   ],
   "source": [
    "X = both_dtm.toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "titles = df_both.index.values\n",
    "\n",
    "print(type(X), X.sum(), X.shape) # an array may be needed for lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 7394\n",
      "INFO:lda:vocab_size: 3031\n",
      "INFO:lda:n_words: 591620\n",
      "INFO:lda:n_topics: 5\n",
      "INFO:lda:n_iter: 1500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -5075575\n",
      "INFO:lda:<10> log likelihood: -4630994\n",
      "INFO:lda:<20> log likelihood: -4491901\n",
      "INFO:lda:<30> log likelihood: -4430139\n",
      "INFO:lda:<40> log likelihood: -4393164\n",
      "INFO:lda:<50> log likelihood: -4369894\n",
      "INFO:lda:<60> log likelihood: -4354611\n",
      "INFO:lda:<70> log likelihood: -4343500\n",
      "INFO:lda:<80> log likelihood: -4334337\n",
      "INFO:lda:<90> log likelihood: -4327494\n",
      "INFO:lda:<100> log likelihood: -4322840\n",
      "INFO:lda:<110> log likelihood: -4319536\n",
      "INFO:lda:<120> log likelihood: -4314655\n",
      "INFO:lda:<130> log likelihood: -4312751\n",
      "INFO:lda:<140> log likelihood: -4309404\n",
      "INFO:lda:<150> log likelihood: -4308907\n",
      "INFO:lda:<160> log likelihood: -4305176\n",
      "INFO:lda:<170> log likelihood: -4304190\n",
      "INFO:lda:<180> log likelihood: -4301987\n",
      "INFO:lda:<190> log likelihood: -4298440\n",
      "INFO:lda:<200> log likelihood: -4298081\n",
      "INFO:lda:<210> log likelihood: -4295932\n",
      "INFO:lda:<220> log likelihood: -4295322\n",
      "INFO:lda:<230> log likelihood: -4292705\n",
      "INFO:lda:<240> log likelihood: -4292415\n",
      "INFO:lda:<250> log likelihood: -4290904\n",
      "INFO:lda:<260> log likelihood: -4290704\n",
      "INFO:lda:<270> log likelihood: -4291230\n",
      "INFO:lda:<280> log likelihood: -4289304\n",
      "INFO:lda:<290> log likelihood: -4287765\n",
      "INFO:lda:<300> log likelihood: -4288304\n",
      "INFO:lda:<310> log likelihood: -4287759\n",
      "INFO:lda:<320> log likelihood: -4287387\n",
      "INFO:lda:<330> log likelihood: -4287208\n",
      "INFO:lda:<340> log likelihood: -4286944\n",
      "INFO:lda:<350> log likelihood: -4285775\n",
      "INFO:lda:<360> log likelihood: -4285702\n",
      "INFO:lda:<370> log likelihood: -4285941\n",
      "INFO:lda:<380> log likelihood: -4286338\n",
      "INFO:lda:<390> log likelihood: -4284202\n",
      "INFO:lda:<400> log likelihood: -4285158\n",
      "INFO:lda:<410> log likelihood: -4283599\n",
      "INFO:lda:<420> log likelihood: -4284542\n",
      "INFO:lda:<430> log likelihood: -4284103\n",
      "INFO:lda:<440> log likelihood: -4283571\n",
      "INFO:lda:<450> log likelihood: -4281558\n",
      "INFO:lda:<460> log likelihood: -4282353\n",
      "INFO:lda:<470> log likelihood: -4281052\n",
      "INFO:lda:<480> log likelihood: -4281848\n",
      "INFO:lda:<490> log likelihood: -4280749\n",
      "INFO:lda:<500> log likelihood: -4277668\n",
      "INFO:lda:<510> log likelihood: -4278520\n",
      "INFO:lda:<520> log likelihood: -4277217\n",
      "INFO:lda:<530> log likelihood: -4276310\n",
      "INFO:lda:<540> log likelihood: -4278679\n",
      "INFO:lda:<550> log likelihood: -4276258\n",
      "INFO:lda:<560> log likelihood: -4275741\n",
      "INFO:lda:<570> log likelihood: -4277327\n",
      "INFO:lda:<580> log likelihood: -4275329\n",
      "INFO:lda:<590> log likelihood: -4275835\n",
      "INFO:lda:<600> log likelihood: -4274838\n",
      "INFO:lda:<610> log likelihood: -4276058\n",
      "INFO:lda:<620> log likelihood: -4276565\n",
      "INFO:lda:<630> log likelihood: -4276360\n",
      "INFO:lda:<640> log likelihood: -4275641\n",
      "INFO:lda:<650> log likelihood: -4275047\n",
      "INFO:lda:<660> log likelihood: -4274617\n",
      "INFO:lda:<670> log likelihood: -4274250\n",
      "INFO:lda:<680> log likelihood: -4273044\n",
      "INFO:lda:<690> log likelihood: -4272205\n",
      "INFO:lda:<700> log likelihood: -4272888\n",
      "INFO:lda:<710> log likelihood: -4273978\n",
      "INFO:lda:<720> log likelihood: -4274649\n",
      "INFO:lda:<730> log likelihood: -4273149\n",
      "INFO:lda:<740> log likelihood: -4274555\n",
      "INFO:lda:<750> log likelihood: -4274370\n",
      "INFO:lda:<760> log likelihood: -4271704\n",
      "INFO:lda:<770> log likelihood: -4273765\n",
      "INFO:lda:<780> log likelihood: -4271062\n",
      "INFO:lda:<790> log likelihood: -4271631\n",
      "INFO:lda:<800> log likelihood: -4272345\n",
      "INFO:lda:<810> log likelihood: -4271385\n",
      "INFO:lda:<820> log likelihood: -4269275\n",
      "INFO:lda:<830> log likelihood: -4269459\n",
      "INFO:lda:<840> log likelihood: -4269357\n",
      "INFO:lda:<850> log likelihood: -4271777\n",
      "INFO:lda:<860> log likelihood: -4271353\n",
      "INFO:lda:<870> log likelihood: -4271414\n",
      "INFO:lda:<880> log likelihood: -4270142\n",
      "INFO:lda:<890> log likelihood: -4270816\n",
      "INFO:lda:<900> log likelihood: -4269900\n",
      "INFO:lda:<910> log likelihood: -4270548\n",
      "INFO:lda:<920> log likelihood: -4270989\n",
      "INFO:lda:<930> log likelihood: -4270146\n",
      "INFO:lda:<940> log likelihood: -4270763\n",
      "INFO:lda:<950> log likelihood: -4271990\n",
      "INFO:lda:<960> log likelihood: -4269494\n",
      "INFO:lda:<970> log likelihood: -4269852\n",
      "INFO:lda:<980> log likelihood: -4269474\n",
      "INFO:lda:<990> log likelihood: -4271383\n",
      "INFO:lda:<1000> log likelihood: -4270434\n",
      "INFO:lda:<1010> log likelihood: -4269884\n",
      "INFO:lda:<1020> log likelihood: -4270071\n",
      "INFO:lda:<1030> log likelihood: -4269088\n",
      "INFO:lda:<1040> log likelihood: -4271661\n",
      "INFO:lda:<1050> log likelihood: -4270275\n",
      "INFO:lda:<1060> log likelihood: -4270812\n",
      "INFO:lda:<1070> log likelihood: -4269697\n",
      "INFO:lda:<1080> log likelihood: -4269204\n",
      "INFO:lda:<1090> log likelihood: -4269124\n",
      "INFO:lda:<1100> log likelihood: -4268456\n",
      "INFO:lda:<1110> log likelihood: -4268243\n",
      "INFO:lda:<1120> log likelihood: -4267827\n",
      "INFO:lda:<1130> log likelihood: -4267814\n",
      "INFO:lda:<1140> log likelihood: -4266773\n",
      "INFO:lda:<1150> log likelihood: -4268923\n",
      "INFO:lda:<1160> log likelihood: -4267119\n",
      "INFO:lda:<1170> log likelihood: -4267753\n",
      "INFO:lda:<1180> log likelihood: -4265562\n",
      "INFO:lda:<1190> log likelihood: -4264466\n",
      "INFO:lda:<1200> log likelihood: -4267582\n",
      "INFO:lda:<1210> log likelihood: -4265922\n",
      "INFO:lda:<1220> log likelihood: -4265728\n",
      "INFO:lda:<1230> log likelihood: -4266550\n",
      "INFO:lda:<1240> log likelihood: -4264378\n",
      "INFO:lda:<1250> log likelihood: -4265302\n",
      "INFO:lda:<1260> log likelihood: -4266665\n",
      "INFO:lda:<1270> log likelihood: -4266213\n",
      "INFO:lda:<1280> log likelihood: -4265106\n",
      "INFO:lda:<1290> log likelihood: -4266206\n",
      "INFO:lda:<1300> log likelihood: -4265037\n",
      "INFO:lda:<1310> log likelihood: -4265647\n",
      "INFO:lda:<1320> log likelihood: -4265809\n",
      "INFO:lda:<1330> log likelihood: -4265545\n",
      "INFO:lda:<1340> log likelihood: -4265676\n",
      "INFO:lda:<1350> log likelihood: -4266795\n",
      "INFO:lda:<1360> log likelihood: -4265757\n",
      "INFO:lda:<1370> log likelihood: -4264263\n",
      "INFO:lda:<1380> log likelihood: -4264294\n",
      "INFO:lda:<1390> log likelihood: -4263254\n",
      "INFO:lda:<1400> log likelihood: -4264936\n",
      "INFO:lda:<1410> log likelihood: -4264319\n",
      "INFO:lda:<1420> log likelihood: -4262681\n",
      "INFO:lda:<1430> log likelihood: -4262621\n",
      "INFO:lda:<1440> log likelihood: -4261941\n",
      "INFO:lda:<1450> log likelihood: -4261361\n",
      "INFO:lda:<1460> log likelihood: -4262515\n",
      "INFO:lda:<1470> log likelihood: -4263771\n",
      "INFO:lda:<1480> log likelihood: -4261618\n",
      "INFO:lda:<1490> log likelihood: -4261026\n",
      "INFO:lda:<1499> log likelihood: -4259620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: like/feel/life/get/time/year/thing/even/depression/day/really/know/work/job/make/go/people/going/thought/friend\n",
      "Topic 1: friend/year/would/time/got/mom/told/one/said/back/day/go/dad/parent/month/kill/never/school/last/week\n",
      "Topic 2: one/care/emptiness/mountain/climb/http/river/cheap/friendship/enjoyable/afternoon/consciousness/45/happened/drifting/private/face/continuously/heaven/everywhere\n",
      "Topic 3: want/feel/like/know/life/im/people/fucking/even/get/think/dont/anymore/really/hate/die/make/friend/much/everything\n",
      "Topic 4: nt/m/s/ve/ca/want/like/feel/know/life/people/ll/get/even/anymore/think/would/make/fucking/d\n"
     ]
    }
   ],
   "source": [
    "# get topics with LDA\n",
    "import numpy as np\n",
    "import lda\n",
    "\n",
    "model = lda.LDA(n_topics=5, n_iter=1500, random_state=1) # the topics get quite blurry once we combine the two dataframes...\n",
    "# going with 5 for now (tried 3-5; all have overlapping words but with three there's essentially no difference)\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 20\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, '/'.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The five topics in the combined dataframe include\n",
    "\n",
    "- depressed? work?\n",
    "- friends and parents? school?\n",
    "- lonely; life is too challenging\n",
    "- anger\n",
    "- also anger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the top topic of each post\n",
    "doc_topic = model.doc_topic_\n",
    "topic_index = {0:'work', 1: 'school', 2:'lonely', 3:'anger', 4:'also_anger'}\n",
    "topic_count = {v : 0 for v in topic_index.values()}\n",
    "for i in range(len(titles)):\n",
    "    topic_count[topic_index[doc_topic[i].argmax()]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'work': 3252, 'school': 829, 'lonely': 6, 'anger': 2140, 'also_anger': 1167}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # check each topic\n",
    "# for i in range(len(titles)):\n",
    "#     if doc_topic[i].argmax() == 4:\n",
    "#         print(df_both['Combined'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Comment:** In general, the topics in r/depression are __slightly__ more clear cut; that said, everything overlaps quite a bit in both subreddits. Moreover, the topics in the combined dataframe are not at all obvious. I would hesitate to conclude the topics in the two subreddits can be distinguished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
